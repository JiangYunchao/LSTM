#-*- coding:utf-8-*-
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
sys.path.insert(0, '/home/jiang/polyvore_Bi-LSTM')
from utils.data_utils import load_pkl
from utils.data_utils import DataFile
import numpy as np
import nltk
import nltk.data
from nltk.tokenize import WordPunctTokenizer
import json

tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')



class preprocess_text:

    def __init__(self, state):
        self.state = state  #train, val, test

    # def create_vocab(self, filename):
    #     """Creates the vocabulary of word to word_id.
    #     """
    #     # Create the vocabulary dictionary.
    #     word_counts = open(filename).read().splitlines()
    #     reverse_vocab = [x.split('\t')[0] for x in word_counts]
    #     unk_id = len(reverse_vocab)
    #     vocab_dict = dict([(x, y) for (y, x) in enumerate(reverse_vocab)])
    #     vocab = Vocabulary(vocab_dict, unk_id)
    #
    #     return vocab

    def load_data(self):
        datafile = DataFile('/data/polyvore/processed/tuples',
                            '/data/polyvore/processed/image_list')
        image_list = datafile.image_list
        fashion_sets, fashion_items = load_pkl('/data/polyvore/processed/pickles')
        positive_tuple, negative_tuples = datafile.get_tuples(self.state, repeated=False)
        return image_list, positive_tuple, negative_tuples, fashion_items

    def set_dic(self, set_tuple, image_list, fashion_items):
        all_sets = []
        for i, tpl in enumerate(set_tuple):
            single_set = {}
            single_set["set_id"] = i
            single_set["username"] = tpl[0]
            single_set["item"] = []
            for j in range(1, 4):
                single_item = {}
                single_item["index"] = j
                single_item["id"] = tpl[j]
                image_name = image_list[j - 1][tpl[j]]
                single_item["imgname"] = image_name
                item_info = fashion_items[image_name]
                if j == 1:
                    single_item["category"] = "top"
                elif j == 2:
                    single_item["category"] = "bottom"
                else:
                    single_item["category"] = "shoe"

                single_item['name'] = item_info['name']
                single_item['text'] = tokenizer.tokenize(item_info['text'])
                single_set["item"].append(single_item)
            all_sets.append(single_set)
        print('Found %d fashion sets.' % (len(all_sets)))
        return all_sets


    def process_word(self, text):
        ts = [',', '.', ';', '(', ')', '?', '!', '&', '%', ':', '*', '"']
        for t in ts:
            text = text.replace(t, ' ' + t + ' ')
        return text


    def get_vocab(self, all_sets):
        special_words = ['<EOS>', '<UNK>']
        vocab = []
        for sets in all_sets:
            for item in sets["item"]:
                if item["text"]:
                    for sentence in item["text"]:
                        sentence = self.process_word(sentence)
                        words = list(set(WordPunctTokenizer().tokenize(sentence)))
                        vocab += words
        vocab = list(set(vocab))
        vocab_final = special_words + vocab

        with open ('vocab.txt', 'w') as f:
            for word in vocab_final:
                f.write(word + '\n')
            print("Vocab Write Down Finished...")


    def get_text(self, all_sets, set_tuple):
        des = []
        for sets in all_sets:
            username = sets['username']
            for item in sets["item"]:
                if item["text"]:
                    index = item['index']
                    text = str(username) + "/" + str(index) + "/" + str(item["id"]) + "/"
                    for sentence in item["text"]:
                        sentence = self.process_word(sentence)
                        text += sentence + '\t'
                    des.append(text)
                    
        with open ('data_' + self.state + '.txt', 'w') as f:
            for record in des:
                f.write(record + '\n')
            print("Text Write Down Finished...")

if __name__ == ('__main__'):
    a = preprocess_text("train")
    image_list, positive_tuple, negative_tuples, fashion_items = a.load_data()
    all_sets = a.set_dic(positive_tuple, image_list, fashion_items)
    a.get_vocab(all_sets)
    a.get_text(all_sets, positive_tuple)
    
    
